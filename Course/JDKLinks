1 - Install JDK

Download and install JDK from the following web site 

https://www.oracle.com/java/technologies/javase/jdk11-archive-downloads.html

Jdk 11 is recommended for Spark Scala


After the installation, check via terminal

2 - Download IDEA 

Download and install idea community edition from here : 


https://www.jetbrains.com/idea/download


3 - Maven Project

GroupId:net.alchim31.maven
ArtifactId:scala-archetype-simple
Version:1.7


    val spark = SparkSession.builder().master("local").appName("SparExample").getOrCreate();
    val rdd = spark.sparkContext.textFile("/Users/serkan/Desktop/Course/Spark/data/foo");

    println("Count : " + rdd.count())
    println("First : " + rdd.first())



 --add-exports java.base/sun.nio.ch=ALL-UNNAMED
 
 
 --Winutils
 https://github.com/steveloughran/winutils/blob/master/hadoop-2.7.1/bin/winutils.exe
 
 https://github.com/steveloughran/winutils
 
 --Environment variable
 HADOOP_HOME	C:\winutil\
 
 
 
 
 
