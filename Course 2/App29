package org.example

import org.apache.log4j.{Level, Logger}
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.types.{IntegerType, StringType, StructField, StructType}


object App29 {

  def main(args: Array[String]): Unit = {

    val rootLogger = Logger.getRootLogger()
    rootLogger.setLevel(Level.ERROR)
    Logger.getLogger("org.apache.spark").setLevel(Level.ERROR)
    Logger.getLogger("org.spark-project").setLevel(Level.ERROR)


    val spark = SparkSession.builder.master("local").
      appName("SparkStreaming").getOrCreate()


    val schema = StructType(
      Array(
        StructField("sn",StringType,true),
        StructField("type",IntegerType,true),
        StructField("value1", StringType,true),
        StructField("value2", StringType,true)
      )
    )


    //listen folder
    val df = spark.readStream.option("sep",",").schema(schema).
      csv("/Users/serkan/Desktop/Training2/data/stream");

    val result = df.select("sn","value2").where("value1=='+'")

    val query = result.writeStream.format("console").start()

    query.awaitTermination()

  }

}
